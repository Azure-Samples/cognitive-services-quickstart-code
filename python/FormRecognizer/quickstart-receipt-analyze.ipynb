{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook gives you an end-to-end example on how to get started using Python SDK to analyze a receipt with Azure Form Recognizer."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Prerequistes\n",
    "- Azure subscription - [Create one for free](https://azure.microsoft.com/en-us/free/cognitive-services/)\n",
    "- [Python 3.x](https://www.python.org/) - Your Python installation should include [pip](https://pip.pypa.io/en/stable/). You can check if you have pip installed by running `pip --version` on the command line. Get pip by installing the latest version of Python.\n",
    "- Once you have your Azure subscription, [create a Form Recognizer resource](https://ms.portal.azure.com/#create/Microsoft.CognitiveServicesFormRecognizer) in the Azure portal to get your **key** and **endpoint**. After it deploys, click **Go to resource** - You will need the key and endpoint from the resource you create to connect your application to the Form Recognizer API. Later in the quickstart, you will paste your key and endpoint into the code below. You can use the free pricing tier (`F0`) to try the service, and upgrade later to a paid tier (`S0`) for production."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up - Install the client library\n",
    "After installing Python, you can install the latest version of Form Recognier client library with:\n",
    "`pip3 install --upgrade azure-ai-formrecognizer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install --upgrade azure-ai-formrecognizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the key and endpoint\n",
    "Refer to the screenshot on how to get the key and endpoint of your Form Recognizer resource.\n",
    "![How to find endpoint and key](./images/how-to-find-endpoint-and-key.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "FORMRECOGNIZER_ENDPOINT = \"{enter your endpoint}\"\n",
    "FORMRECOGNIZER_KEY = \"{enter your key}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authenticate a FormRecognizerClient for document analysis\n",
    "[FormRecognizerClient](https://docs.microsoft.com/en-us/python/api/azure-ai-formrecognizer/azure.ai.formrecognizer.formrecognizerclient?view=azure-python) is used to query the service to recongize document fields and conent like key-value pairs, tables with prebuilt or custom trained models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.ai.formrecognizer import FormRecognizerClient, FormField\n",
    "\n",
    "# Initiate client with given endpoint and credential\n",
    "client = FormRecognizerClient(FORMRECOGNIZER_ENDPOINT, AzureKeyCredential(FORMRECOGNIZER_KEY))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start an analyze request for your local files with `begin_recognize_receipts`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: succeeded, Document(s): 1\n"
     ]
    }
   ],
   "source": [
    "# Read the sample image file into memory\n",
    "IMAGE_FILE = 'sample-retail-receipt.png'\n",
    "with open(IMAGE_FILE, 'rb') as f:\n",
    "    data = f.read()\n",
    "\n",
    "# Send request to Form Recognizer service to process data\n",
    "task = client.begin_recognize_receipts(data)\n",
    "\n",
    "# Get the analyze result\n",
    "analyzed_result = task.result()\n",
    "print('Status: {}, Document(s): {}'.format(task.status(), len(analyzed_result)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## You can also analyze files from the web using `begin_recognize_receipts_from_url`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: succeeded, Document(s): 1\n"
     ]
    }
   ],
   "source": [
    "IMAGE_URL = 'https://raw.githubusercontent.com/Azure-Samples/cognitive-services-REST-api-samples/master/curl/form-recognizer/contoso-receipt.png'\n",
    "\n",
    "# Send request to Form Recognizer service to process data\n",
    "task = client.begin_recognize_receipts_from_url(IMAGE_URL)\n",
    "\n",
    "# Get the analyze result\n",
    "analyzed_result = task.result()\n",
    "print('Status: {}, Document(s): {}'.format(task.status(), len(analyzed_result)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract information from analyzed result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Receipt Items:\n",
      "...Item #1\n",
      "......Name: Surface Pro 6 has confidence 0.914\n",
      "......Quantity: 1.0 has confidence 0.971\n",
      "......TotalPrice: 999.0 has confidence 0.983\n",
      "...Item #2\n",
      "......Name: SurfacePen has confidence 0.718\n",
      "......Quantity: 1.0 has confidence 0.976\n",
      "......TotalPrice: 99.99 has confidence 0.967\n",
      "MerchantAddress: 123 Main Street Redmond, WA 98052 has confidence 0.975\n",
      "MerchantName: Contoso has confidence 0.974\n",
      "MerchantPhoneNumber: None has confidence 0.988\n",
      "ReceiptType: Itemized has confidence 0.99\n",
      "Subtotal: 1098.99 has confidence 0.982\n",
      "Tax: 104.4 has confidence 0.985\n",
      "Total: 1203.39 has confidence 0.957\n",
      "TransactionDate: 2019-06-10 has confidence 0.987\n",
      "TransactionTime: 13:59:00 has confidence 0.985\n"
     ]
    }
   ],
   "source": [
    "for receipt in analyzed_result:\n",
    "    for name, field in receipt.fields.items():\n",
    "        if name == \"Items\":\n",
    "            print(\"Receipt Items:\")\n",
    "            for idx, items in enumerate(field.value):\n",
    "                print(\"...Item #{}\".format(idx + 1))\n",
    "                for item_name, item in items.value.items():\n",
    "                    print(\"......{}: {} has confidence {}\".format(item_name, item.value, item.confidence))\n",
    "        else:\n",
    "            print(\"{}: {} has confidence {}\".format(name, field.value, field.confidence))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next steps\n",
    "- Learn [Receipt concept](https://docs.microsoft.com/en-us/azure/cognitive-services/form-recognizer/concept-receipts)\n",
    "- Explore the [different offerings](https://docs.microsoft.com/en-us/azure/cognitive-services/form-recognizer/overview) in Form Recognizer\n",
    "- Try Form Recognizer with [sample tool](https://docs.microsoft.com/en-us/azure/cognitive-services/form-recognizer/quickstarts/get-started-with-form-recognizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4cd7ab41f5fca4b9b44701077e38c5ffd31fe66a6cab21e0214b68d958d0e462"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
